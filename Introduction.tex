\section{Introduction}

TV archives maintained by national institutions such as the French INA, the Netherlands Institute for Sound \& Vision, or the British Broadcasting Corporation are rapidly growing in size. The need for applications that make these archives searchable has led researchers to devote concerted effort to developing technologies that create indexes.

Because human nature leads people to be very interested in other people.
Indexes that represent the location and identity of people in the archive are indispensable for searching archives.
%
To this end, started in 2011, the REPERE challenge aimed at supporting research on multimodal person recognition~\cite{BERNARD--SLAM--2013, KAHN--CBMI--2012}. Its main goal was to answer the two questions \emph{``who speaks when?''} and \emph{``who appears when?''} using any available source of information (including pre-existing biometric models and person names extracted from text overlay and speech transcripts). 
%
Thanks to this challenge and the associated multimodal corpus~\cite{GIRAUDEL--LREC--2012}, significant progress was achieved in either supervised or unsupervised multimodal person recognition~\cite{BECHET--INTERSPEECH--2014, BENDRIS--CBMI--2013, BREDIN--ODYSSEY--2014, BREDIN--INTERSPEECH--2013, BREDIN--SLAM--2013, BREDIN--IJMIR--2014, FAVRE--SLAM--2013, GAY--CBMI--2014, POIGNANT--ASLP--2015, POIGNANT--SLAM--2013, POIGNANT--INTERSPEECH--2012, POIGNANT--MTAP--2015, ROUVIER--CBMI--2014}.

However, when the content is created or broadcast, it is not always possible to predict which people will be the most important to find in the future and biometric models may not yet be available at indexing time The goal of this task is thus to address the challenge of indexing people in the archive under real-world conditions, \emph{i.e.} when there is no pre-set list of people to index.
%
To emphasize on the importance of unsupervised person discovery, a ``Multimodal Person Discovery in Broadcast TV'' task was proposed \cite{POIGNANT--MEDIAEVAL--2015,tocite}. In this task, participants are provided with a collection of TV broadcast recordings pre-segmented into shots. Each shot $s \in \shots$ has to be automatically tagged with the names of people both speaking and appearing at the same time during the shot.
%
Because the list of people is not provided in advance, their names have to be found in the audio (\emph{e.g.}, using speech transcription -- ASR) or visual (\emph{e.g.}, using optical character recognition -- OCR) streams.
%
This makes the task completely unsupervised (\emph{i.e.} using algorithms not relying on pre-existing labels or biometric models).

What are the problems to solve here?

What are the contributions?

\endinput
