\section{Introduction}

TV archives maintained by national institutions such as the French INA, the Netherlands Institute for Sound \& Vision, or the British Broadcasting Corporation are rapidly growing in size. The need for applications that make these archives searchable has led researchers to devote concerted effort to developing technologies that create indexes.

Because human nature leads people to be very interested in other people.
Indexes that represent the location and identity of people in the archive are indispensable for searching archives.
%
To this end, started in 2011, the REPERE challenge aimed at supporting research on multimodal person recognition~\cite{BERNARD--SLAM--2013, KAHN--CBMI--2012}. Its main goal was to answer the two questions \emph{``who speaks when?''} and \emph{``who appears when?''} using any available source of information (including pre-existing biometric models and person names extracted from text overlay and speech transcripts). 
%
Thanks to this challenge and the associated multimodal corpus~\cite{GIRAUDEL--LREC--2012}, significant progress was achieved in either supervised or unsupervised multimodal person recognition~\cite{BECHET--INTERSPEECH--2014, BENDRIS--CBMI--2013, BREDIN--ODYSSEY--2014, BREDIN--INTERSPEECH--2013, BREDIN--SLAM--2013, BREDIN--IJMIR--2014, FAVRE--SLAM--2013, GAY--CBMI--2014, POIGNANT--ASLP--2015, POIGNANT--SLAM--2013, POIGNANT--INTERSPEECH--2012, POIGNANT--MTAP--2015, ROUVIER--CBMI--2014}.

However, when the content is created or broadcast, it is not always possible to predict which people will be the most important to find in the future and biometric models may not yet be available at indexing time The goal of this task is thus to address the challenge of indexing people in the archive under real-world conditions, \emph{i.e.} when there is no pre-set list of people to index.
%
To emphasize on the importance of unsupervised person discovery, a ``Multimodal Person Discovery in Broadcast TV'' task was proposed \cite{POIGNANT--MEDIAEVAL--2015,tocite}. In this task, participants are provided with a collection of TV broadcast recordings pre-segmented into shots. Each shot $s \in \shots$ has to be automatically tagged with the names of people both speaking and appearing at the same time during the shot.
%
Because the list of people is not provided in advance, their names have to be found in the audio (\emph{e.g.}, using speech transcription -- ASR) or visual (\emph{e.g.}, using optical character recognition -- OCR) streams.
%
This makes the task completely unsupervised (\emph{i.e.} using algorithms not relying on pre-existing labels or biometric models).

In order to successfully tag the shots with the correct identities, one must find a way to assign a name correctly to a presence of the corresponding person, then that name must also be propagated to all the shots during which that person appears and speaks. For this purpose, there are 3 possible approaches:
\begin{compactitem}
\item{Clustering-based name assignment: Face/speech tracks are first aggregated into homogeneous clusters according to person identities. Then each clusters is tagged with the most probable person name.}
\item{Verification-based name propagation: A person name is first assigned to the most probable face/speech track. The name is then propagated to all face/speech tracks which are verified to have the same identity.}
\item{Graph-based name propagation: A graph is built with a face/speech track as a node and weight of edges is the similarity. Some nodes are initially tagged with the names. Names are then propagated along the edges within the graph.}
\end{compactitem}

Although these approaches share some common components in face / speech representation, each has charateristic ...

In this paper, the authors investigate all 3 approaches with their variations.
\endinput
